---
title: 'Lab 4: optimising linear algebra'
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(leaps)
```

Linear algebra is fundamental for data science. Standard CPUs aren't very good at it: they can spend nearly all the time getting data on and off the CPU and very little time doing productive calculations. Specially designed chips for matrix operations (GPUs) and higher-dimensional tensor operations (TPUs) are the future way around this problem, but optimising data flow is important even there.

The basic idea is to partition a matrix into blocks, chosen to match features of the computer such as cache size.  It's hard to derive the optimal block size from first principles, so optimisation is done by measuring many problems of different sizes and trying to fit a model of some sort to find the best settings.

The data (`sgemm_product.csv`) is the result of an exhaustive experiment (`Readme.txt`) in optimising matrix-matrix multiplication for a particular GPU. There are 14 predictor variables in 261400 possible combinations. For each combination there are timings for four runs of multiplying two $2048\times 2048$ matrices. Typically we would not have such exhaustive data, so we want to know how good the prediction from a subsample will be.

You will model `log(time)`, not `time`, because that's what the experiment was designed for. The effects of the variables should be closer to multiplicative than additive.

Some useful code for setting up the design matrix and doing the cross-validation is on Canvas for this lab.

## Tasks

1. Read in the data and choose your own random sample of 500 rows with

```{r cache=TRUE}
set.seed(427632295)
my_sample <- sample(241600, 500)
sgemm1 <- read_csv("sgemm_product.csv",
                          col_names = c("MWG","NWG","KWG","MDIMC","NDIMC",
                                        "MDIMA","NDIMB","KWI","VWM","VWN",
                                        "STRM","STRN","SA","SB",
                                        "Run1","Run2","Run3","Run4")) |>
  slice(my_sample) |>
  mutate(across(Run1:Run4, as.numeric),
         logrun1 = log(Run1),
         logrun2 = log(Run2),
         logrun3 = log(Run3),
         logrun4 = log(Run4))

```

2. Using the `leaps` package, as in class, run backwards stepwise selection to predict timings from the **logarithm of time** for first run on models with all 14 predictors and all two-way interactions. Look at models with up to 20 variables. Plot the apparent error against the number of predictors. 
```{r cache=TRUE}
mf <- model.frame(logrun1 ~ .^2, data = sgemm1)
X <- model.matrix(logrun1 ~ .^2, mf)[, -1]
regfit <- regsubsets(x = X, y = sgemm1$logrun1,
                     nbest = 1, nvmax = 20, method = "backward")
reg_summary <- summary(regfit)

plot(reg_summary$bic, xlab = "Number of predictors", ylab = "BIC",
     main = "Model size vs BIC")
```


Note that you will need a bit of work to get all 2-way interactions in `regsubsets` as you can't use standard model notatation in regsubsets. That is, `regsubsets` requires a premade design matrix with all the interactions. Below in the code chunk below, see two approaches of making a design matrix with all 2-way  interactions.

```{r eval=FALSE}
## The easy way: get lm to do it
## assuming sgemm1 is your subset of the data frame with the predictors and logged Run 1 times

model <- lm(logrun1~.^2,data=sgemm1)
X<-model.matrix(model)[,-1]  ## drop the intercept column because regsubsets() will put it back in

## Without actually running lm()
## faster, and still works when there are more variables than observations

mf<-model.frame(logrun1~.^2, data=sgemm1)
X<-model.matrix(logrun1~.^2, mf)[,-1]
```


3. Using cross-validation, select a tuning parameter $\lambda$ so that minimising $n\log\mathrm{RSS}+\lambda p$ gives good mean squared prediction error, and select a predictive model.
```{r cache=TRUE}
lambdas <- seq(0, 10, length.out = 20)  # grid of λ
cv_errors <- rep(NA, length(lambdas))

folds <- sample(rep(1:10, length.out = nrow(X)))  # 10-fold CV

for (i in seq_along(lambdas)) {
  lambda <- lambdas[i]
  fold_errs <- c()
  for (k in 1:10) {
    train <- folds != k
    test <- folds == k
    regfit_cv <- regsubsets(x = X[train, ], y = sgemm1$logrun1[train],
                            nvmax = 20, method = "backward")
    # pick best model under current λ
    reg_summary <- summary(regfit_cv)
    n <- sum(train)
    p <- 1:length(reg_summary$rss)   # number of predictors in each model
    crit <- n * log(reg_summary$rss) + lambda * p
    best_size <- which.min(crit)
    # refit on train set, test on test set
    # use coef() to extract model, then predict
    # compute MSE on test set
  }
  cv_errors[i] <- mean(fold_errs)
}

plot(lambdas, cv_errors, type="b")
```

4. Estimate the actual mean squared prediction error of your model using the second replicate of the experiment (`log(Run2)`) in your sample data set.
```{r cache=TRUE}
preds <- predict(final_model, newdata = sgemm1)
mse_sample <- mean((sgemm1$logrun2 - preds)^2)
```

5. Estimate the actual mean squared prediction error of your model using the second replicate of the experiment (`log(Run2)`) on all 261400 observations. How does this value compare to the estimate you found in question 4?
```{r cache=TRUE}
preds_all <- predict(final_model, newdata = sgemm_product)
mse_all <- mean((sgemm_product$logrun2 - preds_all)^2)
```
## Computational hints

In `rmarkdown`, you can start a code chunk with `{r cache=TRUE}` instead of just `{r}`. It will then not be re-run unless something changes. This can save a lot of time when working with large datasets.